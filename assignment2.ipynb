{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WeCeITXoxLf"
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
    "\n",
    "**Keywords**: Sexism Detection, Multi-class Classification, LLMs, Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFN9Q2rGLJnc"
   },
   "source": [
    "\n",
    "# Contact\n",
    "\n",
    "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
    "\n",
    "Teaching Assistants:\n",
    "\n",
    "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
    "* Eleonora Mancini -> e.mancini@unibo.it\n",
    "\n",
    "Professor:\n",
    "\n",
    "* Paolo Torroni -> p.torroni@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN4nmQacznGV"
   },
   "source": [
    "# Relevant Material\n",
    "\n",
    "- Tutorial 3\n",
    "- Huggingface documentation\n",
    "- Huggingface hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ck47wFhrLJnc"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "You are tasked to address the [EDOS Task B](https://github.com/rewire-online/edos) on sexism detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mtjp0cGLJnc"
   },
   "source": [
    "## Problem definition\n",
    "\n",
    "Given an input text sentence, the task is to label the sentence as not-sexist or one of these four sexist categories: (1) threats, (2)  derogation, (3) animosity, (4) prejudiced discussion.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "**Text**: *``Schedule a date with her, then don't show up. Then text her \"GOTCHA B___H\".''*\n",
    "\n",
    "**Label**: Threats\n",
    "\n",
    "**Text**: *``That’s completely ridiculous a woman flashing her boobs is not sexual assault in the slightest.''*\n",
    "\n",
    "**Label**: Not sexist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dqwRZx-QNGX"
   },
   "source": [
    "## Approach\n",
    "\n",
    "We will tackle the five-class classification task with LLMs.\n",
    "\n",
    "In particular, we'll consider zero-/few-shot prompting approaches to assess the capability of some popular open-source LLMs on this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PS3igwXpQcAY"
   },
   "source": [
    "## Preliminaries\n",
    "\n",
    "We are going to download LLMs from [Huggingface](https://huggingface.co/).\n",
    "\n",
    "Many of these open-source LLMs require you to accept their \"Community License Agreement\" to download them.\n",
    "\n",
    "In summary:\n",
    "\n",
    "- If not already, create an account of Huggingface (~2 mins)\n",
    "- Check a LLM model card page (e.g., [Mistral v3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)) and accept its \"Community License Agreement\".\n",
    "- Go to your account -> Settings -> Access Tokens -> Create new token -> \"Repositories permissions\" -> add the LLM model card you want to use.\n",
    "- Save the token (we'll need it later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alhHgn7LhcR6"
   },
   "source": [
    "## Setup and dependencies installation\n",
    "\n",
    "In the following, we will assume that you have \n",
    "- created a local python virtual environment - either with python [venv](https://docs.python.org/3/library/venv.html) module or via [uv](https://github.com/astral-sh/uv) (preferred) - with the `ipykernel` or `jupyter` packages pre-installed to start the jupyter kernel;\n",
    "- a stable internet connection\n",
    "Nothing else is needed.\n",
    "\n",
    "We will now download the `pyproject.toml` file specifying the project dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "synYz5AThcR8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_project_root() -> Path:\n",
    "    \"\"\"Return the root directory of the project.\"\"\"\n",
    "    start_dir = Path.cwd()\n",
    "\n",
    "    markers = [\"assignment2.ipynb\"]\n",
    "\n",
    "    for path in [start_dir, *list(start_dir.parents)]:\n",
    "        for marker in markers:\n",
    "            if (path / marker).exists():\n",
    "                return path\n",
    "\n",
    "    return start_dir\n",
    "\n",
    "\n",
    "project_root: Path = get_project_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUYRVC63hcR-"
   },
   "outputs": [],
   "source": [
    "project_repo: str = \"mpreda01/nlp-assignments\"\n",
    "project_branch: str = \"main\"\n",
    "pyproject_url = (\n",
    "    f\"https://raw.githubusercontent.com/{project_repo}/{project_branch}/pyproject.toml\"\n",
    ")\n",
    "lockfile_url = (\n",
    "    f\"https://raw.githubusercontent.com/{project_repo}/{project_branch}/uv.lock\"\n",
    ")\n",
    "urllib.request.urlretrieve(pyproject_url, project_root / \"pyproject.toml\")  # noqa: S310\n",
    "urllib.request.urlretrieve(lockfile_url, project_root / \"uv.lock\");  # noqa: S310"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23e45rDnhcSA"
   },
   "source": [
    "If using [uv](https://github.com/astral-sh/uv) (recommended) you can now install the dependencies to a local virtual environment at `.venv` simply via\n",
    "```sh\n",
    "uv sync --extra assignment2\n",
    "```\n",
    "\n",
    "If not, the same can be achieved with the usual python [venv](https://docs.python.org/3/library/venv.html):\n",
    "```sh\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "(.venv) pip install \".[assignment2]\" \n",
    "```\n",
    "\n",
    "Make sure to do the above and *restart the kernel* if necessary before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqjLdamAhcSA"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login, whoami\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkPeTgHbhcSB"
   },
   "source": [
    "### Huggingface Login\n",
    "\n",
    "Once we have created an account and an access token, we need to login to Huggingface via code. Add an environment variable `HF_TOKEN` with your token\n",
    "```sh\n",
    "export HF_TOKEN=\"my-huggingface-token-with-the-correct-access-rights\"\n",
    "```\n",
    "as [expected by huggingface](https://huggingface.co/docs/huggingface_hub/package_reference/environment_variables#hftoken).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUqtrKAJhcSC",
    "outputId": "b13497f9-b6fd-4677-b8ff-8ad7860383f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as @niccolozanotti\n",
      "Profile page: https://huggingface.co/niccolozanotti\n"
     ]
    }
   ],
   "source": [
    "hf_token: str = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "if hf_token:\n",
    "    try:\n",
    "        login(token=hf_token, add_to_git_credential=True)\n",
    "        user = whoami(token=hf_token)\n",
    "        username = user[\"name\"]\n",
    "        print(f\"Logged in as @{username}\")\n",
    "        print(f\"Profile page: https://huggingface.co/{username}\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid token.\")\n",
    "    except ImportError:\n",
    "        print(\"ipywidgets not installed.\")\n",
    "else:\n",
    "    print(\"Warning: 'HF_TOKEN' environment variable not set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLxSrY-4e_0J"
   },
   "source": [
    "After login, you can download all models associated with your access token in addition to those that are not protected by an access token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEYMBnAQLJnc"
   },
   "source": [
    "### Data Loading\n",
    "\n",
    "Since we are only interested in prompting, we do not require a train dataset.\n",
    "\n",
    "We have preparared a small test set version of EDOS in our dedicated [Github repository](https://github.com/lt-nlp-lab-unibo/nlp-course-material).\n",
    "\n",
    "Check the ``Assignment 2/data`` folder.\n",
    "It contains:\n",
    "\n",
    "- ``a2_test.csv`` → a small test set of 300 samples.\n",
    "- ``demonstrations.csv`` -> a batch of 1000 samples for few-shot prompting.\n",
    "\n",
    "Both datasets contain a balanced number of sexist and not sexist samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5XyOcFGLJnd"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "We require you to:\n",
    "\n",
    "* **Download** the ``A2/data`` folder.\n",
    "* **Encode** ``a2_test.csv`` into a ``pandas.DataFrame`` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MrVjj23hcSF",
    "outputId": "49821426-1ba8-4a5d-c476-14df40c837bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /Users/niccolozanotti/software/github.com/nlp-project/data/a2_test.csv\n",
      "Saved to: /Users/niccolozanotti/software/github.com/nlp-project/data/demonstrations.csv\n",
      "Loaded 300 test samples\n"
     ]
    }
   ],
   "source": [
    "repo: str = \"nlp-unibo/nlp-course-material\"\n",
    "branch: str = \"main\"\n",
    "folder_path: str = \"2025-2026/Assignment%202/data\"\n",
    "data_dir: Path = project_root / \"data\"\n",
    "files = [\"a2_test.csv\", \"demonstrations.csv\"]\n",
    "\n",
    "base_url = f\"https://raw.githubusercontent.com/{repo}/{branch}/{folder_path}\"\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for filename in files:\n",
    "    url = f\"{base_url}/{filename}\"\n",
    "    destination = data_dir / f\"{filename}\"\n",
    "    urllib.request.urlretrieve(url, destination)  # noqa: S310\n",
    "    print(f\"Saved to: {destination}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/a2_test.csv\")\n",
    "print(f\"Loaded {len(test_df)} test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJp08l4yLJnd"
   },
   "source": [
    "# [Task 1 - 0.5 points] Model setup\n",
    "\n",
    "Once the test data has been loaded, we have to setup the model pipeline for inference.\n",
    "\n",
    "In particular, we have to:\n",
    "- Load the model weights from Huggingface\n",
    "- Quantize the model to fit into a single-GPU limited hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptffotFIjq89"
   },
   "source": [
    "## Which LLMs?\n",
    "\n",
    "The pool of LLMs is ever increasing and it's impossible to keep track of all new entries.\n",
    "\n",
    "We focus on popular open-source models.\n",
    "\n",
    "- [Mistral v2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)\n",
    "- [Mistral v3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)\n",
    "- [Llama v3.1](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct)\n",
    "- [Phi3-mini](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)\n",
    "- [TinyLlama](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)\n",
    "- [DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B)\n",
    "- [Qwen3](https://huggingface.co/Qwen/Qwen3-1.7B)\n",
    "\n",
    "Other open-source models are more than welcome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uH1YShLfLJnd"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "In order to get Task 1 points, we require you to:\n",
    "\n",
    "* Pick 2 model cards from the provided list.\n",
    "* For each model:\n",
    "  - Setup a quantization configuration for the model.\n",
    "  - Load the model via HuggingFace APIs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8ORld7klCfG"
   },
   "source": [
    "### Note\n",
    "\n",
    "There's a popular library integrated with Huggingface's ``transformers`` to perform quantization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d99f8f9e8fa046a599bef86a67696dec",
      "e991a24a1d374fc48bba0755362b70f2",
      "a1df1790baf24ae39c70505face7ecae",
      "07569e7ce06d497d8198e69dd781daa8",
      "19049ed871fa45b7814951ab370477f2",
      "80c2dd533f3d466fbdbc67e45bfbabcb",
      "c728604d6789430a868f831b9d36dabc",
      "634ae6a3d3e547dd879e302f7a175ca0",
      "9162245147124ade81747c05456d02c4",
      "9a277e3a36ce41788dc180d62e2f9229",
      "e93618cadfc54ab594d1043bfc0aadaf",
      "7b694898ef4f41ab941eda33302291a6",
      "6eac3100033d4cbe8acd2cc934cd655f",
      "98edcf4591cb4d19a0988613bf2e69b3",
      "a9d5d8c9e4da4609a9abdd4c7a3f7154",
      "81ba69a27f334f7ca9ed32a011f5f898",
      "c2384ffe10d54f23bd1bab4b6fdcce83",
      "da4907106c4c4c71954f21dcd2cfc745",
      "1b47fd9fafb7491cb9f60fdc6fc561be",
      "be282525c78e4fb3906ae595e84f299a",
      "0a9f44e1a05b4048a69ac2040928b81c",
      "e168da74ea244489bb0889ebd4dcfd5b",
      "30db37d7b12740708ac8cb2d0b08862c",
      "abe0f071977240e29406dd95dbc4e862",
      "067b979cdc4c4ebb9de1b7f402689105",
      "ba9d5dae7a9a47dc80d538df8031a11b",
      "fbb919cd39dc48f586a634c920cc65fe",
      "eeb5c19bdf4d434882fce4d65d448ad7",
      "fcf0872474eb43338564de872a32009e",
      "3db6992f4b2c4cde869ba844d3bf6088",
      "842d486121d84971ac752afde67d502c",
      "3ec223730f534a5da17a1810f50b79f5",
      "3981e3b2d7e74ebeb36b0b7edd7ce7a0",
      "d0bdb7af76d946c98720eb815b9a41cd",
      "83b02d95038f4ce5a3e97a11df960548",
      "3287ca150cd0440193fbb8cd0b45ea74",
      "50886b25fc3d4bf7b1a9c416bf881f3f",
      "303c281520954682907eafe201ba17bb",
      "3605d99081bc48b1a82840bec6247a87",
      "2bf23a7cf2c042cabea09af163b06825",
      "3ccd7a3eb71a4e129bfc8866b422171e",
      "ef05f2f85bf143628e84dbade9462bc8",
      "bd5868980b374ac892d5bd7247e376ad",
      "204064ea01a540268df1b4bcfbecf41a",
      "286e93f2bbf9423e89df6361edbe2a98",
      "6cd3990613f8425f90d2974df8376f47",
      "acda171e40d942b69ed14fa24ac7e636",
      "66866a81dcba40599b90a94222e029ed",
      "6fddc89972fe4dfb8fb76d8a0133ca1a",
      "8c3cc4720d9f486aa3b633e5a91b3cd2",
      "d22cf9c919254604adcaab3817480783",
      "f23e0ffc44854c6c94386f64708a70a8",
      "7119f67b44834e5abec8dfe6ff479738",
      "07c8f71259d144bfa8d1fccf4763fcb9",
      "44725f6a36d74c76937e30c707ce8486",
      "281ca71c334f42a69cc6edf2bce6cd16",
      "f8fccc4f2e0c44d79ff648e67d299430",
      "a60fceca5721434daf11788d2a7ca911",
      "00955d5de2b74c829dc8ce38b61cda36",
      "1d259527098c473697f0433ecd52e0e3",
      "41d9689f65b6471da2cb4a9ce60e95a5",
      "b655f8221b79446aaf907890d50ab750",
      "dbf0620c40bd49fab95611bc195cb6e7",
      "bd4967d5abf34d91bb08b893870b4706",
      "638876435f6c44f086e2342d02e6c941",
      "2094bed3ddc44164bca9dcd8360759ff",
      "6e9f67e4efe548c4adb4e89caafec43f",
      "509fdaaebaac409e9c899ab47585c1ff",
      "cea041209f4c494c9106d9158b9803a7",
      "935a76ff7fd94527b3e0c1213511f976",
      "add4aaf9f24c4c44823ab9ce83e2d991",
      "c5c190460e5d42fead7ec488ca9af398",
      "cc25d1f3728f4759b0a251dfda19df84",
      "a0971b2299f449c2b893002e19d9ef7c",
      "e3cca108b2d14e4c88fe53849721ea69",
      "59d6583f00fb43f49233ec120a0ce9d9",
      "8ddc11ac75c94c6eb9792481982b79de",
      "d02c86bdb8b94bb4b49967659b2fa96b",
      "9d1eb3890d344afd954777a28f7d3403",
      "25596b777c7d4fc6af7c25b168539c9f",
      "23bb9e0b01fb4323bd9c4daf6e965212",
      "2b4c957fab8e470298d79245dfa6747d",
      "4cb8f41b5f754150a19b18ac776c3313",
      "be7ddcaa243b4449988683d13b2c18ab",
      "273a4812ad1943c2af0f3e96857b9913",
      "2cb840be5c994f7192f44809b5e96957",
      "5f18df7cc19e43b695e4c9ee486fb6bb",
      "b74a4e3d1b5d4ff0893bd4b75845fdb8",
      "4638c00f3f594b529c78d693b00ff1ef",
      "0821ac5603bb495495015f6b0fdd19ce",
      "2974243492ce40b89c3ecf46a21a7f2e",
      "038acb472dd546b6b9431fec2afe9d70",
      "fac0dd4013844fc5b701488d6f85073e",
      "7929d14598344802a1102642ad4d813d",
      "28dc8ee826e142b2a66b6dcc9a11a938",
      "3d116e021503435aa84f35d3ea4556fd",
      "82d5216e0ea84ace9772de789a8ce1ef",
      "e7d9725703654d10981ad39bd952a5a5",
      "a1f20b98634b427ca3525b8f0551d8f3",
      "b5e547ae53b24363b19d54ee526ac232",
      "24f024471336499194aefac19632653a",
      "e5f799c89d574d2bb32078c8ff4fe7aa",
      "c264832b7d1648999ef102ec37488bc1",
      "8ac24583891c49e7a13123471ae0c063",
      "9c093265279f47088a9c18fc50434971",
      "d9776b7c96e343128122b904f956cdf7",
      "4b13f7516042428b8786287f92b121b1",
      "3d6f2d93d83f499bacd1e8e3ca111e71",
      "432795f376814bdcb530595390fc2d37",
      "3906e5bc00bd455783f2090feb10bf52",
      "0bbc46280f2a42e59bb888a384f97456",
      "7c420333d0a148a99e0c5f2cc6cc8e50",
      "dc0087647ed045e6822ab7216ffa3690",
      "ae02bf80d52f4cc9a1eda6aa119e5b07",
      "b087bfdf9a8a47f0b2ad3bdd9b67f312",
      "f410a7af4d814dbfab556f81b82d156a",
      "3816abd3302c405586787f9ed1c751a6",
      "a11e9118e42a43dbb6781088a1acb1e8",
      "7159f2822e4a49988255a8208c4c0178",
      "f0d078a96e4f4badb4d3c2fb24296812",
      "2f1ebff2e5034a44b7fbeaef7e5bc68d",
      "5b62154403f14a4f9186eab8c20e127d",
      "1af4b59075344c999625e97ecf1ab77b",
      "db5b4f22e78c4e27a96c811f723b56f1",
      "752c51feed8848d89ee9dac457640778",
      "b6497bc2aa0c4074b88f344e14e2936a",
      "c1ed292df0d14efb8044f9932650a620",
      "1e0da9e9c4d243f0b2b56f341dbf9e21",
      "bf6cabfb5700415ca4104e53d7756490",
      "c485e0ca998c40e3b51deb2d05e1fca1",
      "667b1b00f9d448268312919e108ae709",
      "3c01a60a57ad47f59276c276b814b6b4",
      "36c04e91ba6b41eba3aefe403110e3fe",
      "6d024c10c6834190aaa9c1fbaf07d66b",
      "1552d0ee6f254220b25cd3d581d376dc",
      "deea10908c224f04b665c23e1b9c52a7",
      "c2237f4f1ccc4931bbe1425812eb3060",
      "d8b08ccb0c9b43f397de8211fa204364",
      "b9f6dc3122044d8c9289b4feaf45f647",
      "0c65407b27d147dd9265ca52e60b566f",
      "02fea01bfaef4621882a109dcf8b9d7a",
      "fb165a8b1af04618b509de56b3d0251d",
      "6de47f97cbd34d8ab29aa3470a4d32b0",
      "1b937393d8fb41d5a669b16d028b4b26",
      "c1ffc78d1cea45cb9244514983691a8f",
      "a8bfed9a78ea4d42b0f3383f800b444e",
      "13483eeb9dbd46948b25c86fe2c27f1c",
      "5fc27b899cb946caa64e00eac4bc19bb",
      "82a0f29bc5184e2296d33579f21f9713",
      "5af0e0975e064f01a0ec8c1b225d26e7",
      "ea309340218d4dca97a76b3c9676f4ed",
      "9346944a6b9c4f00881b31015efd9d73",
      "c6e291abb6c74ee6962d54d13fbc14d1",
      "9e7ee4dc5fb24b74aca2f293eed86512",
      "08268ea43fcd4b5aa48066908765aff6",
      "3f4e5dc5565b4f9aa8ae001ccce837a9",
      "5013661d1c1d4ba7b3f6210db008eb86",
      "2510539e1b01472697da9f500e18c79f",
      "1d228d67f5b1414aa3c5e49fc2f1f26e",
      "57d91e4bded64b7fac6ae9aa31deec11",
      "12fdf36bf0144adb8b681658267d72e9",
      "4f79e3a36bfb410c868dacb7f96252a1",
      "0897dd2e4ae742e29532930efea823ed",
      "9d2fe314798649cea9cfc3e5cf1a16b3",
      "13b84d6228df4d09844b227bb47b1eba",
      "b28aaf9f8afb4641905d5372b8e9844a",
      "4f1bf329cbb44550b3f35d85082c38a2",
      "146d259380dc4ddcab109604b9fb517d",
      "ae8ec4a10f004fdeb77fa8535065d58f",
      "d7cb1a726b734448b303d8b82d158aff",
      "f4d16ec02d89404798174af5e38ee638",
      "885a28bd678b409090055bd8ca4f786d",
      "8de6fcdefd25487c94869c75dd2053b7",
      "c8e63135e60c400c833957624da27a76",
      "1997431c4e8c42c9be6aa6823f783e4c",
      "f047c9ba816b4ba291f35329c85a62ee",
      "ed508bd98aed4cb3ac2a4e1362285f2e",
      "a7680153091d46a3bd8563607db268e2",
      "af9bc5f18e824fb581c0a7f1db3b5d95",
      "28a00ca503cb4bd5b2ace5bea3b15068",
      "934a9ad538c64f66939fc1ee66ddfeb6",
      "d1bdd3f4f6994b1282e4e89dce3b1a30",
      "69f1dca35de14c6092a55f12883f2039",
      "b4fcabc274ce467492a33f2f76d6296c",
      "9278e9421f654c8db6007c5af844d484",
      "6dadca86e3cc4f4badd021125a6276e2",
      "b074485d175d4b14be07694197a38d87",
      "fb9ddd3a96724251ab69394d4dc66993",
      "2cebe369811a4357b6809005da08e396",
      "2d05410383b54e0e90723a66bf032108",
      "5a05909f2bfc4303bb05e7f5460afed0",
      "bcef9d74faab4d19be64b7676e6127bf",
      "b369f5fda6a644d8a39ab0fc7e770b34",
      "388f03b77cba47e6ab249eed933b5928",
      "680138d70c6146ea83cfa9aa7d2500cc",
      "d4560bc2663c45ce99d9ebebd8702d35",
      "8620541875194716a832aa8b44923329",
      "6d7307675570476cb940fd315edd1199",
      "283232fec6984ac68c4d356a4e8b1492",
      "e6b60544916346588b7f780776fd076c",
      "5f04e0f0946444f182d3742cad1b2eab",
      "75c6182360d54630a21ceed63c1ccee4",
      "ede6c17e00074897bd9de05a0de9685f",
      "53cbe8a1fb754260b0fd1b7b25a65029",
      "c9fc00a8d7e3425fbb853130956c55f3",
      "5e48cada517f47e0b2a9a98eac30c6ad",
      "bf309f6fd1214567a234057af3fcadaf",
      "b2db6a9eae0142eeb3fe0fb2a064dfdb",
      "b89ee8f8500e474d9fee4cc247e6b178",
      "0218c94ba6e24759bae3fc26d56af1c2",
      "15d9369b3475471d892d6b35502d78a3",
      "5467a2454b514fe286065a5aceeedf6d",
      "c59bd50ea28548b2b417c0b7fdab4aa2",
      "018a00ac722947c281c674d489c03e91",
      "870479b25c6c4d38a8ca9478cae63afc",
      "4eb586e243884bc2aee3e56fd91466c9",
      "436f1f58fb9b47ce8547181ab76bd283",
      "2ff8e2900b844039ac350923a0000e01",
      "a6a043542c8f4bb3bb32dab3bb9f9a64",
      "f5520aa80ad24d05a3419bc1d1063b31",
      "65f9a3795859480c9fabd31d6dcd34c3",
      "f4ec862d81bd4964aae1ef8583702969",
      "b779c5b081214a6dbb45fd454abebe11",
      "40e4e487b8d849d99a007cc787cc00ef",
      "44992c24d7a64a17977b6330c7793223",
      "dc999ce1fd84453587cdbc2aab500d36",
      "678ea89d4bc946658d7b023e75c694df",
      "57a221dfd3b04b14b84428733999eaff",
      "9a659bb5f393441eb4a06bf7ac6db93f",
      "74afe69533004ffd8e5d72e29f27c22c",
      "da5367e4301e48498dc503dd265d055f",
      "42067ae186704ab8b2e121097bf6157f",
      "ffde8b5d7ff640708f1f1fd70c52b5f6",
      "08a4199c9b8046bd93d9ac32bf9a52f7",
      "8d3145c514be416087f7dec19048badc",
      "5d6e58c863b54a118f0b93afdefdf33c",
      "e8cb6f2d10e2446f8ca933c4588cb7b4",
      "6937e4ae2e4046be875f875c454fda2f",
      "5e1dcd8b3fc745f5ab7a4be29091f843",
      "5f5d39e496db43609485db93dc1c38a7",
      "3ee9914ef9d34765b727feff8df70ba7",
      "58d86690978e41e0a46a4908e657fee6",
      "71b31bfe0c744ee78f2e5d5130303606",
      "01818cd1fd334620bc34acccf840032d",
      "22b6910fffef409b8acc0721ef77de66",
      "974020614132469d8dc0c8a77f2fe8f9",
      "6ec91ed3558d44d593003d6ea7b64747",
      "83bafb5351574e99b75e7f2aa0394cb8",
      "18269150d78d454d86b082fb5e7f064e",
      "6ed57aac84f64d449775b5f3a5cca5b4",
      "976c4924fa0542288c7446d4eed006ac",
      "50c9e3785c0f40aa8ea6f23c9d5295f9",
      "c02dce4c82b2418f8063017106a1f13c",
      "5c9dfc709c0d4c479e4df54e76f400a7",
      "5b84181e6f0540f6aae783d398ee883f",
      "9d44ef6e356d44fb88bb2f56130b2938",
      "9a3f13b90a9c49ffb2279e26c4bd8ed1",
      "b57261f6d6b24058ad83df24c44bd439",
      "a2f79ce7ad744b52908e37a050bb858e",
      "39bb77edabc5472b965f5c3c9bcde5e0",
      "b5c0b05138ac4d73a5588e9437e81365",
      "5f069aecd64946bf93f89b76324068c6",
      "077bf606dd774b558dc64c9c87469176",
      "254129536c5446c880ff36a93040b408",
      "78866ce6669649fba93cbe82d0216146",
      "93dddfcb5d154ae79d3f506e03c18ec0",
      "0a26adc7c64447159673ca852e1667e8",
      "b9a7bf5bf9b14befb04348e7c2e8c4b0",
      "a10b26736b594a22b1cba80d5d2ac8f3",
      "868b60aa71314d0db212029b4d6f414e",
      "5ad183a54009437993f77ba79c86e324",
      "7aedc9ff71a44ab3976fb5fa69baf5fd",
      "e54a5907fccb4d2ca8904654177fd4d7",
      "990bb31e244a44f891be01f7bd03c739",
      "762d17af168d4e7bbdf8755ec0f1a7a7"
     ]
    },
    "id": "1A1PPVoIhcSI",
    "outputId": "2ca25389-1fcf-4749-d023-96bfed43c99d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model 1: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99f8f9e8fa046a599bef86a67696dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b694898ef4f41ab941eda33302291a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30db37d7b12740708ac8cb2d0b08862c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bdb7af76d946c98720eb815b9a41cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286e93f2bbf9423e89df6361edbe2a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/680 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281ca71c334f42a69cc6edf2bce6cd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9f67e4efe548c4adb4e89caafec43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02c86bdb8b94bb4b49967659b2fa96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-000002.safetensors:   0%|          | 0.00/8.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4638c00f3f594b529c78d693b00ff1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-000002.safetensors:   0%|          | 0.00/6.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e547ae53b24363b19d54ee526ac232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbc46280f2a42e59bb888a384f97456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 loaded successfully!\n",
      "Loading Model 2: mistralai/Mistral-7B-Instruct-v0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b62154403f14a4f9186eab8c20e127d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c04e91ba6b41eba3aefe403110e3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b937393d8fb41d5a669b16d028b4b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08268ea43fcd4b5aa48066908765aff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28aaf9f8afb4641905d5372b8e9844a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed508bd98aed4cb3ac2a4e1362285f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9ddd3a96724251ab69394d4dc66993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283232fec6984ac68c4d356a4e8b1492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0218c94ba6e24759bae3fc26d56af1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f9a3795859480c9fabd31d6dcd34c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42067ae186704ab8b2e121097bf6157f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b31bfe0c744ee78f2e5d5130303606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9dfc709c0d4c479e4df54e76f400a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78866ce6669649fba93cbe82d0216146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# --- Model 1: DeepSeek ---\n",
    "MODEL_1_ID = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "\n",
    "if \"model_DeepSeek\" not in globals() or model_DeepSeek is None:\n",
    "    print(f\"Loading Model 1: {MODEL_1_ID}\")\n",
    "\n",
    "    tokenizer_DeepSeek = AutoTokenizer.from_pretrained(MODEL_1_ID, force_download=True)\n",
    "    model_DeepSeek = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_1_ID,\n",
    "        return_dict=True,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    # Attach tokenizer to model object\n",
    "    model_DeepSeek.tokenizer = tokenizer_DeepSeek\n",
    "\n",
    "    if tokenizer_DeepSeek.pad_token is None:\n",
    "        tokenizer_DeepSeek.pad_token = tokenizer_DeepSeek.eos_token\n",
    "\n",
    "    print(\"Model 1 loaded successfully!\")\n",
    "else:\n",
    "    print(f\"Model 1 ({MODEL_1_ID}) already loaded, skipping...\")\n",
    "\n",
    "\n",
    "# --- Model 2: Mistral V3---\n",
    "MODEL_2_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "if \"model_mistral\" not in globals() or model_mistral is None:\n",
    "    print(f\"Loading Model 2: {MODEL_2_ID}\")\n",
    "\n",
    "    tokenizer_mistral = AutoTokenizer.from_pretrained(MODEL_2_ID, force_download=True)\n",
    "    model_mistral = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_2_ID,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "        return_dict=True,\n",
    "    )\n",
    "    # Attach tokenizer to model object\n",
    "    model_mistral.tokenizer = tokenizer_mistral\n",
    "\n",
    "    if tokenizer_mistral.pad_token is None:\n",
    "        tokenizer_mistral.pad_token = tokenizer_mistral.eos_token\n",
    "\n",
    "    print(\"Model 2 loaded successfully!\")\n",
    "else:\n",
    "    print(f\"Model 2 ({MODEL_2_ID}) already loaded, skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzNNzb1VLJnd"
   },
   "source": [
    "# [Task 2 - 1.0 points] Prompt setup\n",
    "\n",
    "Prompting requires an input pre-processing phase where we convert each input example into a specific instruction prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GaBtKXomY_m"
   },
   "source": [
    "## Prompt Template\n",
    "\n",
    "Use the following prompt template to process input texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7e8P-Kk8me6q"
   },
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an annotator for sexism detection.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Your task is to classify input text as not-sexist\n",
    "         or sexist. If sexist, classify input text according to one\n",
    "         of the following four categories: threats, derogation,\n",
    "         animosity, prejudiced discussion.\n",
    "\n",
    "         Below you find sexist categories definitions:\n",
    "         Threats: the text expresses intent or desire to harm a woman.\n",
    "         Derogation: the text describes a woman in a derogative manner.\n",
    "         Animosity: the text contains slurs or insults towards a woman.\n",
    "         Prejudiced discussion: the text expresses supports for\n",
    "         mistreatment of women as individuals.\n",
    "\n",
    "         Respond only by writing one of the following categories:\n",
    "         not-sexist, threats, derogation, animosity, prejudiced.\n",
    "\n",
    "        TEXT: {text}\n",
    "\n",
    "        ANSWER:\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHeoEN7MLJnd"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "In order to get Task 2 points, we require you to:\n",
    "\n",
    "* Write a ``prepare_prompts`` function as the one reported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUjRVMtMm9CE"
   },
   "outputs": [],
   "source": [
    "def prepare_prompts(texts, prompt_template, tokenizer):\n",
    "    \"\"\"This function format input text samples into instructions prompts.\n",
    "\n",
    "    Inputs:\n",
    "      texts: input texts to classify via prompting\n",
    "      prompt_template: the prompt template provided in this assignment\n",
    "      tokenizer: the transformers Tokenizer object instance associated\n",
    "      with the chosen model card\n",
    "\n",
    "    Outputs:\n",
    "      input texts to classify in the form of instruction prompts\n",
    "    \"\"\"\n",
    "    prepared_prompts = []\n",
    "\n",
    "    for text in texts:\n",
    "        prompt_messages = copy.deepcopy(prompt_template)\n",
    "\n",
    "        prompt_messages[1][\"content\"] = prompt_messages[1][\"content\"].format(text=text)\n",
    "\n",
    "        # Use the tokenizer's chat template to format the messages\n",
    "        # This converts the list of message dicts into the model's expected format\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            prompt_messages,\n",
    "            tokenize=False,  # Return string, not token IDs\n",
    "            add_generation_prompt=True,  # Add the prompt for the model to generate\n",
    "        )\n",
    "\n",
    "        prepared_prompts.append(formatted_prompt)\n",
    "\n",
    "    return prepared_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOCRgGf7mifk"
   },
   "source": [
    "### Notes\n",
    "\n",
    "1. You are free to modify the prompt format (**not its content**) as you like depending on your code implementation.\n",
    "\n",
    "2. Note that the provided prompt has placeholders. You need to format the string to replace placeholders. Huggingface might have dedicated APIs for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgBhkBwuLJnd"
   },
   "source": [
    "# [Task 3 - 1.0 points] Inference\n",
    "\n",
    "We are now ready to define the inference loop where we prompt the model with each pre-processed sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WsrQSvcLJnd"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "In order to get Task 3 points, we require you to:\n",
    "\n",
    "* Write a ``generate_responses`` function as the one reported below.\n",
    "* Write a ``process_response`` function as the one reported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhLBQOOD9STj"
   },
   "outputs": [],
   "source": [
    "# Global label\n",
    "LABEL_MAP = {\n",
    "    \"not-sexist\": 0,\n",
    "    \"threats\": 1,\n",
    "    \"derogation\": 2,\n",
    "    \"animosity\": 3,\n",
    "    \"prejudiced\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bG3CDXNlyD5k"
   },
   "outputs": [],
   "source": [
    "def generate_responses(model, prompt_examples):\n",
    "    \"\"\"This function implements the inference loop for a LLM model.\n",
    "    Given a set of examples, the model is tasked to generate\n",
    "    a response.\n",
    "\n",
    "    Inputs:\n",
    "      model: LLM model instance for prompting\n",
    "      prompt_examples: pre-processed text samples\n",
    "\n",
    "    Outputs:\n",
    "      generated responses\n",
    "    \"\"\"\n",
    "\n",
    "    # Access tokenizer from the model object\n",
    "    tokenizer = model.tokenizer\n",
    "\n",
    "    responses = []\n",
    "    model.eval()\n",
    "\n",
    "    for prompt in tqdm(prompt_examples, desc=\"Generating responses\"):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Define max_new_tokens for generation\n",
    "            # (e.g., a small number for classification answers)\n",
    "            max_new_tokens = (\n",
    "                80 if \"deepseek\" in model.config.name_or_path.lower() else 40\n",
    "            )  # deepseek is a reasoning model and needs more tokens\n",
    "\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "            )\n",
    "\n",
    "        # Decode only the newly generated tokens\n",
    "        generated_tokens = outputs[0][inputs[\"input_ids\"].shape[1] :]\n",
    "        response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "        responses.append(response.strip())\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiCoMrutyXTU"
   },
   "outputs": [],
   "source": [
    "def process_response(response):\n",
    "    \"\"\"This function takes a textual response generated by the LLM\n",
    "    and processes it to map the response to a binary label.\n",
    "\n",
    "    Inputs:\n",
    "      response: generated response from LLM\n",
    "\n",
    "    Outputs:\n",
    "      parsed classification response.\n",
    "      Use the following mapping:\n",
    "      {\n",
    "        'not-sexist': 0,\n",
    "        'threats': 1,\n",
    "        'derogation': 2,\n",
    "        'animosity': 3,\n",
    "        'prejudiced': 4\n",
    "      }\n",
    "    \"\"\"\n",
    "    response_lower = response.lower().strip()\n",
    "\n",
    "    # Extract text after \"ANSWER:\" if present\n",
    "    if \"answer:\" in response_lower:\n",
    "        response_lower = response_lower.split(\"answer:\")[-1].strip()\n",
    "\n",
    "    # For DeepSeek: extract content after </think> if present\n",
    "    if \"</think>\" in response_lower:\n",
    "        response_lower = response_lower.split(\"</think>\")[-1].strip()\n",
    "\n",
    "    for label, idx in LABEL_MAP.items():\n",
    "        if label in response_lower:\n",
    "            return idx\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s5Td5dVV-sMT",
    "outputId": "fc05c0e7-1d9a-4daa-f7f1-81aac00dd038"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|██████████| 300/300 [28:24<00:00,  5.68s/it]\n",
      "Generating responses: 100%|██████████| 300/300 [01:36<00:00,  3.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get texts as a list\n",
    "texts = test_df[\"text\"].tolist()\n",
    "\n",
    "# Prepare prompts\n",
    "prompts_DeepSeek = prepare_prompts(texts, prompt, tokenizer_DeepSeek)\n",
    "prompts_mistral = prepare_prompts(texts, prompt, tokenizer_mistral)\n",
    "\n",
    "# Generate responses\n",
    "responses_DeepSeek = generate_responses(model_DeepSeek, prompts_DeepSeek)\n",
    "responses_mistral = generate_responses(model_mistral, prompts_mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKcQ0ZfO2Fya"
   },
   "source": [
    "## Notes\n",
    "\n",
    "1. According to our tests, it should take you ~10 mins to perform full inference on 300 samples on Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyZ8WU09zz-a"
   },
   "source": [
    "# [Task 4 - 0.5 points] Metrics\n",
    "\n",
    "In order to evaluate selected LLMs, we need to compute performance metrics.\n",
    "\n",
    "We compute **macro F1-score** and the ratio of failed responses generated by models (**fail-ratio**).\n",
    "\n",
    "That is, how frequent the LLM fails to follow instructions and provides incorrect responses that do not address the classification task.\n",
    "\n",
    "In summary, we parse generated responses as follows:\n",
    "- **0** if 'not-sexist'\n",
    "- **1** if 'threats'\n",
    "- **2** if 'derogation'\n",
    "- **3** if 'animosity'\n",
    "- **4** if 'prejudiced'\n",
    "- **0** if the model does not answer in either way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6lu64o80iX4"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "In order to get Task 4 points, we require you to:\n",
    "\n",
    "* Write a ``compute_metrics`` function as the one reported below.\n",
    "* Compute metrics for the two selected LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Fmcw_9v0k9D"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(y_pred, y_true):\n",
    "    \"\"\"This function takes predicted and ground-truth labels and compute\n",
    "    metrics. In particular, this function compute accuracy and\n",
    "    fail-ratio metrics. This function internally invokes\n",
    "    `process_response` to compute metrics.\n",
    "\n",
    "    Inputs:\n",
    "      y_pred: parsed LLM responses\n",
    "      y_true: ground-truth binary labels\n",
    "\n",
    "    Outputs:\n",
    "      dictionary containing desired metrics\n",
    "    \"\"\"\n",
    "    failures = 0\n",
    "    parsed_predictions = []\n",
    "\n",
    "    for response in y_pred:\n",
    "        response_lower = response.lower().strip()\n",
    "\n",
    "        # Check if response contains any valid label\n",
    "        found_label = any(label in response_lower for label in LABEL_MAP)\n",
    "\n",
    "        if not found_label:\n",
    "            failures += 1\n",
    "\n",
    "        parsed_predictions.append(process_response(response))\n",
    "\n",
    "    fail_ratio = failures / len(y_pred)\n",
    "    macro_f1 = f1_score(y_true, parsed_predictions, average=\"macro\")\n",
    "\n",
    "    return {\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"fail_ratio\": fail_ratio,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LFd1RDkLY1m",
    "outputId": "ef313749-a7ef-443d-bc5e-e7006f96ad7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek: {'macro_f1': 0.0659217877094972, 'fail_ratio': 0.0}\n",
      "Mistral: {'macro_f1': 0.3394486079547122, 'fail_ratio': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Get ground truth labels as integers\n",
    "y_true = test_df[\"label_category\"].map(LABEL_MAP).tolist()\n",
    "\n",
    "# Compute metrics\n",
    "metrics_DeepSeek = compute_metrics(responses_DeepSeek, y_true)\n",
    "metrics_mistral = compute_metrics(responses_mistral, y_true)\n",
    "\n",
    "print(\"DeepSeek:\", metrics_DeepSeek)\n",
    "print(\"Mistral:\", metrics_mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHyvV4QD2vZS"
   },
   "source": [
    "# [Task 5 - 1.0 points] Few-shot Inference\n",
    "\n",
    "So far, we have tested models in a zero-shot fashion: we provide the input text to classify and instruct the model to generate a response.\n",
    "\n",
    "We are now interested in performing few-shot prompting to see the impact of providing demonstration examples.\n",
    "\n",
    "To do so, we slightly change the prompt template as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEqsOHz63ReW"
   },
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an annotator for sexism detection.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Your task is to classify input text as not-sexist\n",
    "         or sexist. If sexist, classify input text according to one\n",
    "         of the following four categories: threats, derogation,\n",
    "         animosity, prejudiced discussion.\n",
    "\n",
    "         Below you find sexist categories definitions:\n",
    "         Threats: the text expresses intent or desire to harm a woman.\n",
    "         Derogation: the text describes a woman in a derogative manner.\n",
    "         Animosity: the text contains slurs or insults towards a woman.\n",
    "         Prejudiced discussion: the text expresses supports for\n",
    "         mistreatment of women as individuals.\n",
    "\n",
    "         Respond only by writing one of the following categories:\n",
    "         not-sexist, threats, derogation, animosity, prejudiced.\n",
    "\n",
    "        EXAMPLES: {examples}\n",
    "\n",
    "        TEXT: {text}\n",
    "\n",
    "        ANSWER:\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SnaxuwN3ySF"
   },
   "source": [
    "The new prompt template reports some demonstration examples to instruct the model.\n",
    "\n",
    "Generally, we provide an equal number of demonstrations per class as shown in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mNmRMQs4VCn"
   },
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an annotator for sexism detection.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Your task is to classify input text as not-sexist\n",
    "         or sexist. If sexist, classify input text according to one\n",
    "         of the following four categories: threats, derogation,\n",
    "         animosity, prejudiced discussion.\n",
    "\n",
    "         Below you find sexist categories definitions:\n",
    "         Threats: the text expresses intent or desire to harm a woman.\n",
    "         Derogation: the text describes a woman in a derogative manner.\n",
    "         Animosity: the text contains slurs or insults towards a woman.\n",
    "         Prejudiced discussion: the text expresses supports for\n",
    "         mistreatment of women as individuals.\n",
    "\n",
    "         Respond only by writing one of the following categories:\n",
    "         not-sexist, threats, derogation, animosity, prejudiced.\n",
    "\n",
    "         EXAMPLES:\n",
    "         TEXT: **example 1**\n",
    "         ANSWER: threats\n",
    "         TEXT: **example 2**\n",
    "         ANSWER: not-sexist\n",
    "\n",
    "         TEXT: {text}\n",
    "\n",
    "        ANSWER:\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OE0XnaVr3CZz"
   },
   "source": [
    "## Instructions\n",
    "\n",
    "In order to get Task 5 points, we require you to:\n",
    "\n",
    "- Load ``demonstrations.csv`` and encode it into a ``pandas.DataFrame`` object.\n",
    "- Define a ``build_few_shot_demonstrations`` function as the one reported below.\n",
    "- Modify ``prepare_prompts`` to support demonstrations.\n",
    "- Perform few-shot inference as in Task 3.\n",
    "- Compute metrics as in Task 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oyxypUG3ltH"
   },
   "outputs": [],
   "source": [
    "def build_few_shot_demonstrations(demonstrations, num_per_class=2):\n",
    "    \"\"\"Inputs:\n",
    "      demonstrations: DataFrame wrapping demonstrations.csv\n",
    "      num_per_class: number of demonstrations per class\n",
    "\n",
    "    Outputs:\n",
    "      list of demonstrations to inject into the prompt template.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "\n",
    "    for label in LABEL_MAP:\n",
    "        # Get samples for this label\n",
    "        label_samples = demonstrations[demonstrations[\"label_category\"] == label].head(\n",
    "            num_per_class\n",
    "        )\n",
    "\n",
    "        for _, row in label_samples.iterrows():\n",
    "            examples.append(f\"TEXT: {row['text']}\\nANSWER: {label}\")\n",
    "\n",
    "    return \"\\n\".join(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWksdoZwgr_K",
    "outputId": "9b7d478c-9d58-4050-915a-210c3c86ec2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|██████████| 300/300 [28:59<00:00,  5.80s/it]\n",
      "Generating responses: 100%|██████████| 300/300 [01:58<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek (few-shot): {'macro_f1': 0.07878656554712893, 'fail_ratio': 0.10333333333333333}\n",
      "Mistral (few-shot): {'macro_f1': 0.4748459569093434, 'fail_ratio': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Load demonstrations\n",
    "demonstrations_df = pd.read_csv(data_dir / \"demonstrations.csv\")\n",
    "\n",
    "# 2. Build demonstrations string\n",
    "examples_str = build_few_shot_demonstrations(demonstrations_df, num_per_class=4)\n",
    "\n",
    "# 3. Define few-shot prompt template (with {examples} placeholder filled)\n",
    "few_shot_prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an annotator for sexism detection.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"Your task is to classify input text as not-sexist\n",
    "         or sexist. If sexist, classify input text according to one\n",
    "         of the following four categories: threats, derogation,\n",
    "         animosity, prejudiced discussion.\n",
    "\n",
    "         Below you find sexist categories definitions:\n",
    "         Threats: the text expresses intent or desire to harm a woman.\n",
    "         Derogation: the text describes a woman in a derogative manner.\n",
    "         Animosity: the text contains slurs or insults towards a woman.\n",
    "         Prejudiced discussion: the text expresses supports for\n",
    "         mistreatment of women as individuals.\n",
    "\n",
    "         Respond only by writing one of the following categories:\n",
    "         not-sexist, threats, derogation, animosity, prejudiced.\n",
    "\n",
    "         EXAMPLES:\n",
    "{examples_str}\n",
    "\n",
    "        TEXT: {{text}}\n",
    "\n",
    "        ANSWER:\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# 4. Prepare few-shot prompts\n",
    "prompts_DeepSeek_fewshot = prepare_prompts(texts, few_shot_prompt, tokenizer_DeepSeek)\n",
    "prompts_mistral_fewshot = prepare_prompts(texts, few_shot_prompt, tokenizer_mistral)\n",
    "\n",
    "# 5. Generate responses (few-shot)\n",
    "responses_DeepSeek_fewshot = generate_responses(\n",
    "    model_DeepSeek, prompts_DeepSeek_fewshot\n",
    ")\n",
    "responses_mistral_fewshot = generate_responses(model_mistral, prompts_mistral_fewshot)\n",
    "\n",
    "# 6. Compute metrics (few-shot)\n",
    "metrics_DeepSeek_fewshot = compute_metrics(responses_DeepSeek_fewshot, y_true)\n",
    "metrics_mistral_fewshot = compute_metrics(responses_mistral_fewshot, y_true)\n",
    "\n",
    "print(\"DeepSeek (few-shot):\", metrics_DeepSeek_fewshot)\n",
    "print(\"Mistral (few-shot):\", metrics_mistral_fewshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGpZWQb45XXK"
   },
   "source": [
    "## Notes\n",
    "\n",
    "1. You are free to pick any value for ``num_per_class``.\n",
    "\n",
    "2. According to our tests, few-shot prompting increases inference time by some minutes (we experimented with ``num_per_class`` $\\in [2, 4]$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHuT1a1GLJnd"
   },
   "source": [
    "# [Task 6 - 1.0 points] Error Analysis\n",
    "\n",
    "We are now interested in evaluating model responses and comparing their performance.\n",
    "\n",
    "This analysis helps us in understanding\n",
    "\n",
    "- Classification task performance gap: are the models good at this task?\n",
    "- Generation quality: which kind of responses do models generate?\n",
    "- Errors: which kind of mistakes do models do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kjEAHD4LJne"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "In order to get Task 6 points, we require you to:\n",
    "\n",
    "* Compare classification performance of selected LLMs in a Table.\n",
    "* Compute confusion matrices for selected LLMs.\n",
    "* Briefly summarize your observations on generated responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QWlVXJgLJne"
   },
   "source": [
    "# [Task 7 - 1.0 points] Report\n",
    "\n",
    "Wrap up your experiment in a short report (up to 2 pages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fsdV99TLJne"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Use the NLP course report template.\n",
    "* Summarize each task in the report following the provided template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-hUXYaLLJne"
   },
   "source": [
    "### Recommendations\n",
    "\n",
    "The report is not a copy-paste of graphs, tables, and command outputs.\n",
    "\n",
    "* Summarize classification performance in Table format.\n",
    "* **Do not** report command outputs or screenshots.\n",
    "* Report learning curves in Figure format.\n",
    "* The error analysis section should summarize your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fURV8zfPLJne"
   },
   "source": [
    "# Submission\n",
    "\n",
    "* **Submit** your report in PDF format.\n",
    "* **Submit** your python notebook.\n",
    "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zn1tUeYzLJne"
   },
   "source": [
    "# FAQ\n",
    "\n",
    "Please check this frequently asked questions before contacting us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYAOVGvKhtTQ"
   },
   "source": [
    "### Model cards\n",
    "\n",
    "You can pick any open-source model card you like.\n",
    "\n",
    "We recommend starting from those reported in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWG72N-LLJne"
   },
   "source": [
    "### Implementation\n",
    "\n",
    "Everything can be done via ``transformers`` APIs.\n",
    "\n",
    "However, you are free to test frameworks, such as [LangChain](https://www.langchain.com/), [LlamaIndex](https://www.llamaindex.ai/) [LitParrot](https://github.com/awesome-software/lit-parrot), provided that you correctly address task instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g1R7ObKhcSu"
   },
   "source": [
    "### Task Performance\n",
    "\n",
    "The task is challenging and zero-shot prompting may show relatively low performance depending on the chosen model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coy_pJ40LJne"
   },
   "source": [
    "### Prompt Template\n",
    "\n",
    "Do not change the provided prompt template.\n",
    "\n",
    "You are only allowed to change it in case of a possible extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSiH0Xqj79wc"
   },
   "source": [
    "### Optimizations\n",
    "\n",
    "Any kind of code optimization (e.g., speedup model inference or reduce computational cost) is more than welcome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cplnq3dLJne"
   },
   "source": [
    "### Bonus Points\n",
    "\n",
    "0.5 bonus points are arbitrarily assigned based on significant contributions such as:\n",
    "\n",
    "- Outstanding error analysis\n",
    "- Masterclass code organization\n",
    "- Evaluate A1 dataset and perform comparison\n",
    "- Perform prompt tuning\n",
    "\n",
    "Note that bonus points are only assigned if all task points are attributed (i.e., 6/6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jpr-LSK7LJnh"
   },
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
